Useful python package.

1. For improving speed of runtime.
Numba, cython(needs complilation), pypy, jax(improved numpy)
JAX(same as numpy but faster)

2. pandas alternative.
dask(good for parallel, memory too)
cudf(GPU pandas)
polars(using rust)
pandaral-lel(parallel process pandas, not memory efficient)
Modin(could be the best of all with pandas, store memory in disk.)
calamine (reading excel file)
Vaex (for big data)
fireducks(faster, not the memory, can use pandas code)
duckDB (use sql)
pd.read_csv('xxxx.py', chucksize=10)
fugue (use pandas to spark, dask, ... of your choice)  See fugue_example.py in this repo.
sqlglot: convert between postgre, duckdb, mysql 

5. Automate machine learning. ***mlxtend can also do feature engineering.
mlxtend, PyCaret, AutoML H2O, 
fastai(deeplearning)
Autogluon 

8. Categorical data for clustering. Kmodes method.
K-prototype=contains both continuous and categorical.

11. Manipulate pandas dataframe with AI.
sketch

12. Timeseries data analysis.
tslearn(clustering & anormaly detection), 
tssearch(find seasonal patterns), 
tsfresh(Automatic feature engineering), 
Kats(Facebook, similar to Pycaret but include prohet & deeplearning), 
lag llama(pre-trained)
AutoGluon(Amazon, similar to Pycaret.  Chronos(LLM zeroshot forecasting) )
Prophet(introduced by Facebook), Neural prophet
DMD(dimensionality reduction)
MLforecast(ensemble with classical models)
TimeFM, xLSTM,   N-beats, NHITS, PatchTST, TSMixer, SOFTS, LagLlama, Nixtla(include Nbeats), Darts(include Nbeats)
neuralforecast(includes LSTM, Nbeats, TimeXer, temporal fusion transformer(maybe best), timesnet(maybe best).  Available through conda)
Liquid neural network(see repo)
xLSTM, TimeFM.  (New timeseries model by Google)
"from statsmodels.tsa.seasonal import seasonal_decompose" to get info.
Use Fourier transform to remove noise.
Use Wavelet(similar to fourier transform) to convert input features to freq domain, then use it as input features.
DeepAR(LSTM or GRU automatic parameter tuning model)
Neural ODE with LSTM.(see repo)
5 useful libraries: Nixtla, Darts, skTime, statsforecast(classical)
Temporal convolutional network 
salesforce-merlion(similar to pycalet with lstm)
tsfeature, tsfel (feature extraction)
Moirai, TimeXL
Latent Gaussian mixture (pip install it)

Timeseries metric 
STL decomposition = metric that includes rmse plus direction.
another metric=rmse+residual 

12. loss function for.
huber(good for outlier)
focal loss (imbalance binary class)
KL divergence entropy loss (output is probability distribution)
Hinge Loss function= used for binary classification.  It tends to put hard threashold than binary cross entropy. (No need to put threashold by users)
Quantile loss= puts confidence interval for timeseries predictions.

13. Dimensionality reduction.
UMAP, PaCMAP, TSNE, EncodeDecoder(see my code dimension_reduction_EncodeDecoder.py)
https://medium.com/@evertongomede/a-comparative-analysis-of-dimensionality-reduction-techniques-in-machine-learning-3389c5103348

14. Memory profiler.
https://pypi.org/project/memory-profiler/(If installing from conda, open /env/Lib/site-packages/memory_profiler.py, moddify as below)
(10) from asyncio import isocoroutinefunction #coroutine 
(1203) with open(filename, encoding="utf-8") as f:
LineProfiler (line by line that shows slowest part of code)
cProfile (show statistics on function execution time)
tracemalloc(run tracemalloc.start() & your_python_code & tracemalloc.stop())
objgraph(run objgraph.show_growth(limit=10) in for loop)
scalene (shows memory line by line)

15. Minimize function with constraints
https://machinelearningmastery.com/lagrange-multiplier-approach-with-inequality-constraints/
https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/constrained-optimization/a/lagrange-multipliers-single-constraint
Scipy differential_evolution

16. New decision tree machine learning technique introduced by Microsoft.
DiCE

17. New scikit learn 
pytabkit 

18. Feature selection 
AutoFeatSelect
ITMO_FS (new library, use neural network)
geaturewiz 

19. Feature importance similar to shap.
lime
omnixai(support tensorflow/pytorch, image/text data)
interpretml(anaconda available)
eli5(anaconda available)
alibi
captum (for pytorch)

20. make classification output probability 
calibrated classification 
venn-abers 

21.  Dealing with imbalance target data for classification model
use class weight

22. MCMC regression to include uncertainty in timeseries prediction curve in plot.
https://medium.com/@abdallahashraf90x/oversampling-for-better-machine-learning-with-imbalanced-data-68f9b5ac2696
Gaussian process
Bayesian deep learning(pyro)
pymc (implement MCMC)
tensorflow probability(see bayesian_network repository)
NGboost (see bayesian_network repository/ngboost_example.py)

23. Finetune with ORPO, new technique.
https://huggingface.co/blog/mlabonne/orpo-llama-3

24. t-test(two continuous data that are different or not, assume Gaussian distribution)
Permutation test: same as t-test, but does not assume Gaussian distribution.
chi-squared test(two categorical data that are different or not)(one binary data that are different from expected ratio(50:50) or not)
Anova test(three continuous data that are different or not)

24. statistical test.
Mann-Kendall test: Find upward/downward trend.
Anderson-Darling test: Check if the data follow normal gaussian distribution.
Dickey-Fuller Test: Test if the timeseries data is stationary or not.

25. clustering 
BIRCH (works for big data )
Gaussian mixture 
Affinity propagation (automatically find number of cluster.)
optics (dbscan cannot address different density, optics can)

27. Mamba, the new neural network that is better than transformer.
    Mamba, package installer that is faster than anaconda.  
    uv is also faster than pip.

27. Feature transformation for training supervised model.
yeo-transformation
signature transformation (use fourier transform)
If using log() that has negative values, apply min_max scaler, then apply log().

28. Find frequent itemset association rules. Use mlxtend library.
https://rstudio-pubs-static.s3.amazonaws.com/282387_0cc72775dbc7433b800fe669a49cf77d.html

30. Automate web browsing with python.
selenium
helium
parcel
pydoll 
playwright (Microsoft)
crawl4ai=LLM web scraping/crawling.  https://ai.gopubby.com/feed-knowlege-of-any-website-to-llm-in-seconds-c19bd69a1718

31. fix format in VScode.
black
ruff

32. decorator to minimize memory.
lru_cashe

34. NLP purging, classification, that can integrate with tensorflow, pytorch.
spacy
textblob (it can give text polarity)

36. Feature engineering (create columns with x1+x2, x1-x2, ...)
featuretools

37. OCR: Extract texts from image
Tesseract= Mature, multilingual, widely used | Struggles with handwriting
EasyOCR=Lightweight, deep learning-based | Slightly less accurate for PDFs
OCRmyPDF=Searchable PDFs, batch-friendly   | PDF-focused only
Keras-OCR=Customizable, end-to-end pipeline | More complex setup
DocTR=Modern, scalable, handwriting OK  | Larger dependencies

38. Create pdf, word, documents.
sphinx, mkdocs, 

39. Manipulate Excel.
pyexcel

40. Get information on timeseries data.
from statsmodels.tsa.seasonal import seasonal_decompose

41. Reduce dimension in linear regression.
Eliminate features with VIF, then check adjusted R2 doesn't change much.  Repeat until VIF are all less than 5.
Eliminate features with high p value and check adjusted R2 increase. (backward elimination)

42. Create document.
sphinx

43. Anaconda archive package.
https://repo.anaconda.com/archive/

44. Poetry alternative.
uv

45. Anormaly detection.
Pyod (many algorithm are avialble)
ADTK (unupervised model for timeseries detection)
TODS (Various algorithm includeing Deeplog & Telemanon for timeseries data)
stumpy (use slide window with euclidean distance.)
Auto-encoder(see my code anomaly_detection_autoEncoder.py)
Isolation tree from scikit learn, and use shap values. (see my code anomaly_detection_isolation_forest.py)
model.fit()
explainer = shap.Explainer(model.decision_function, features)
shap_val = explainer(features.iloc[sample])

46. Fix encoding error & Mojibake.
ftfy

47. Use deque() if python list is too big, and need to use append() pop() a lot.

48. save webpage in pdf.
pdfkit

49. Alternative to Pearson correlation.
Chaterjee correlation

52. Create powerpoint.
python-pptx

53. Generate synthetic data using statistics.
Copula
Variational autoencoder 

54. Parse PDF, DOCX, HTML.
docling(convert pdf, word, ppt, image to json or html)
SmolDocling(small LLM that can parse documents)
pdfplumber 
pymupdf(extract image, texts)
tabula(extract table)

56. Japanese Tokenizer from Conda Install.
sudachipy, fugashi, konoha

57. Use "black formatter" in VS code for formatting.  https://qiita.com/nujust/items/e0985240fd461e5c4c0a
In VScode, if you need to modify settings.json, search settings.json in setting option(click screw icon, click settings).

58. Propensity Score matching (PSM).
Run logistic regression(or any other algorithm), outputs will the probability.  Make clusters based on similar probabilities.  
Check if each groups yield similar output distributions. Examine each clusters.

59. VScode recommended extensions.
DocString generator. TestExplorer(run unit test), SpellChecker, GithubCopilot, VScodePDF(view pdf), ExcelView, BookMark(put checkpoint in code)
Shortcut: Alt+click(multi cursor), Ctrl+F2(select all matched variable), Edit excel

61. check model/data drift
evidently
dro (create model that is robust to data drift)
NannyML(looks for distribution, roc curve, etc to check data drift)
see plot/model_performance_check_graph.py

62. GAM.  Linear combination of spline function for non-linear regression.
Pygam

*******
63. Haystack, Best for setting up documents RAG for LLM.
*******

64. LLM related.
fastembed=embedding library(alternative to huggingface)
promptify=use LLM to get entities+description from sentence.
deepeval=test LLM performance
sentence_transformer(library)
keras_nlp=like AI function in Fabric (Bert, gpt available)
fugashi (japanese spacy)
crewAI, Autogen (for multi-agents)
LangExtract=extract entity and related words (eg. symptom:diabetes)
polygot: entity extraction 
Use markitdown to convert pdf, excel... and let LLM handle
scenexplain=let LLM explain image.
tiktoken=count number of tokens.

65. check which probability distribution fits with your data
distfit

66. hyper parameter optimizaiton
keras_tuner

67. Alternative to synthetic did(synthetic control)
causalpy

68. debug code (it prints out every line of codes)
snoop

69. Impute missing values
KNN imputation
missingno(library)

70. web app
gradio

71. Tabular Transformer (deep learning)
ft transformer

72. Predict survival time.
CoxPHfilter (see cox_suvival_regression.py)

73. model for small dataset.
tabpfn: works well for small data.

74. Image
cv2=let you find edges in image.
imagehash=let you tell two images are similar.

75. AutoEncoder
Anormaly detection, feature dimension reduction. (see /deeplearning folder)

# How to run LightGBM with GPU.
see lightgbm_gpu_usage.py

Interactive: Plotly, Bokeh,
Map: Folium, Cartopy
Web Dashboard: Dash
Flowchart: PyGraphviz
Table: AG_Grid



































